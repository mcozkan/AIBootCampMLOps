import pandas as pd
import kagglehub 
import os
import shutil
import mlflow

def load_data():
    with mlflow.start_run(run_name = "download_dataset"):
        print("=== 1. STEP : LOAD DATA ===")
        print("""Story of Dataset:

Nowadays, network systems play a critical role in all areas, from banking to education, and from healthcare to government institutions. However, these systems have become more vulnerable to cyberattacks than ever before. As a result, intrusion detection has become one of the most important components of cybersecurity.

The UNSW-NB15 dataset was created to enable researchers and developers to design intrusion detection algorithms based on network traffic that closely resembles real-world conditions.

Who Created It?

The dataset was generated by the Cyber Range Lab at the University of New South Wales (UNSW) in Australia.
The IXIA PerfectStorm simulator was used for data generation.
The dataset was created in 2015 and is still frequently used in academic publications today.
How Was the Data Collected?

To create realistic network traffic, both normal user behaviors and cyberattacks were simulated. The simulations were run at different times and on different days to generate data spread across various time periods. Network traffic data was collected to include both normal connections and nine different types of attacks.""")

        # Download latest version
        path = kagglehub.dataset_download("mrwellsdavid/unsw-nb15")
        mlflow.log_param("dataset_path", path)

        print("Path to dataset files:", path)

        csv_files = [f for f in os.listdir(path) if f.endswith(".csv")]
        mlflow.log_param("cvs_files_found", len(csv_files))

        target_file = None
        for f in csv_files:
            if "training-set" in f.lower():
                target_file = f
                break

        if target_file:
            file_path = os.path.join(path, target_file)
            df = pd.read_csv(file_path)
            print("file loaded!...")
            print(df.head())


            dest_dir = "data/raw"
            os.makedirs(dest_dir, exist_ok = True)
            dest_path = os.path.join(dest_dir, os.path.basename(file_path))

            shutil.copy(file_path, dest_path)
            print(f"‚úÖ Copied to project folder: {dest_path}")
            print("‚ÑπÔ∏è Now run this in terminal to track with DVC:")
            print(f"   dvc add {dest_path}")

            mlflow.log_artifact(dest_path, artifact_path = "raw_data")

        else:
            print("‚ùå The csv file is not found! CSV's in Folder:", csv_files)
            mlflow.log_param("status", "file_not_found")
            return "No file found!"

    
        print(f"‚úÖ Dosya boyutu: {df.shape}")
        print(f"‚úÖ Kaydedilen dosya: data/raw/UNSW_NB15_training-set.csv")
    
        # Veri hakkƒ±nda temel bilgiler
        print(f"\nüìä Veri Seti Bilgileri:")
        print(f"- Satƒ±r sayƒ±sƒ±: {len(df)}")
        print(f"- S√ºtun sayƒ±sƒ±: {len(df.columns)}")
        print(f"- S√ºtunlar: {list(df.columns[:5])}...")
        print(f"- Eksik deƒüerler: {df.isnull().sum().sum()}")


        # MLflow log
        mlflow.log_param("rows", len(df))
        mlflow.log_param("columns", len(df.columns))
        mlflow.log_param("first_columns", list(df.columns[:5]))
        mlflow.log_metric("missing_values", int(df.isnull().sum().sum()))


if __name__ == "__main__":
    load_data()